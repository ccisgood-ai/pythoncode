{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    " \n",
    "base_url=\"https://www.icourse163.org/member/login.htm#/webLoginIndex\"\n",
    "driver = webdriver.Chrome(executable_path=\"F:\\Python\\chromedriver.exe\")\n",
    "# driver.maximize_window()\n",
    "driver.get(base_url)\n",
    "\n",
    "#观察慕课网登录页面，默认登录方式是手机验证码，如果需要账号密码登录，则要点击一下“账号密码”按钮\n",
    "#注意：登陆部分在iframe里，且为动态id，参考https://blog.csdn.net/weixin_44342166/article/details/99635635\n",
    "#先找到这个按钮\n",
    "time.sleep(1)  \n",
    "driver.execute_script('window.scrollTo(0, 200)') \n",
    "\n",
    "iframe = driver.find_elements_by_tag_name(\"iframe\")[0]\n",
    "driver.switch_to.frame(iframe)\n",
    "#先找到这个按钮\n",
    "jump = driver.find_element_by_class_name('tab0')\n",
    "#然后点击跳转到账号密码验证登录界面\n",
    "jump.click()  \n",
    "\n",
    "name_input = driver.find_element_by_xpath('//*[@id=\"phoneipt\"]')  #找到输入账号的框框\n",
    "pass_input = driver.find_element_by_css_selector(\"[class='j-inputtext dlemail']\")#找到输入密码的框框\n",
    "login_button = driver.find_element_by_id('submitBtn')# 找到登录按钮\n",
    "\n",
    "username=\"15558859651\"  #这里换成自己的账号\n",
    "password=\"Huangxixi123\"   ##这里换成自己的密码\n",
    "\n",
    "name_input.clear()\n",
    "name_input.send_keys(username)# 填写账号\n",
    "time.sleep(1)  #休眠一下，模拟人工登录，不然可能被拦截\n",
    "pass_input.clear()\n",
    "pass_input.send_keys(password)# 填写密码\n",
    "time.sleep(1)\n",
    "login_button.click()# 点击登录\n",
    "time.sleep(1)\n",
    " \n",
    "# print( driver.get_cookies())#打印cookies\n",
    "# time.sleep(2)\n",
    "# print(driver.title)#打印标题\n",
    "#driver.close()   #关闭浏览器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功进入讨论区\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import requests\n",
    "\n",
    "url_head = 'https://www.icourse163.org/learn/CAU-23004?tid=1003114004#/learn/forumindex'\n",
    "driver.get(url_head)\n",
    "print(\"成功进入讨论区\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1页评论写入成功！\n",
      "第2页评论写入成功！\n",
      "第3页评论写入成功！\n",
      "第4页评论写入成功！\n",
      "第5页评论写入成功！\n",
      "第6页评论写入成功！\n",
      "第7页评论写入成功！\n",
      "第8页评论写入成功！\n",
      "第9页评论写入成功！\n",
      "comment写入成功！\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def get_connect_slow():\n",
    "    driver.switch_to.default_content() # 退出框架\n",
    "    pages = driver.find_elements_by_class_name('zpgi')\n",
    "    totle_page = int(pages[-1].text) #倒数第2个zpgi为最后一页,不一定\n",
    "    rs=[]\n",
    "    for i in range(1,totle_page+1):\n",
    "            url = url_head + '?t=0&p=' + str(i)\n",
    "            driver.get(url)\n",
    "            time.sleep(1)\n",
    "            # 多条内容\n",
    "            comments = driver.find_elements_by_class_name('j-link')\n",
    "            for comment in comments:\n",
    "                rs.append(comment.text)\n",
    "            print('第{}页评论写入成功！'.format(i))\n",
    "    \n",
    "    df =pd.DataFrame(columns=['comment'])\n",
    "    df['comment']=rs\n",
    "    df.to_csv('F:\\comment2.csv', mode='a', header=True)\n",
    "    print('comment写入成功！')\n",
    "    \n",
    "get_connect_slow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "https://www.icourse163.org/learn/CAU-23004?tid=1003114004#/learn/forumindex?t=0&p=1\n",
      "#/learn/forumdetail?pid=1211960415\n",
      "https://www.icourse163.org/learn/CAU-23004?tid=1003114004#/learn/forumdetail?pid=1211960415\n",
      "那重新学习有得是十二周喔\n",
      "重修有些是八周课喔\n",
      "你好，这位学员！按照在线课程的惯例，我们没有安排专门的补考环节。如果不慎没有通过，需要下一轮重修学习。谢谢！\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def get_connect_slow_1():\n",
    "#     driver.switch_to.default_content() # 退出框架\n",
    "    pages = driver.find_elements_by_class_name('zpgi')\n",
    "    totle_page = int(pages[-1].text) #倒数第2个zpgi为最后一页,不一定\n",
    "    print(totle_page)\n",
    "    \n",
    "    for i in range(1,2):\n",
    "            try:\n",
    "                url = url_head + '?t=0&p=' + str(i)\n",
    "                print(url)\n",
    "                driver.get(url)\n",
    "                content = driver.page_source\n",
    "                soup = BeautifulSoup(content,'html.parser')\n",
    "                time.sleep(5)\n",
    "                comment_list=soup.find_all(class_ = 'j-data-list')[1]\n",
    "                \n",
    "                comment_detail = comment_list.find('a', class_='j-link')\n",
    "                a_link = comment_detail.get('href')\n",
    "                print(a_link)\n",
    "                reply_link = url.split('#')[0] + a_link\n",
    "                print(reply_link)\n",
    "                driver_reply = webdriver.Chrome(executable_path='F:\\Python\\chromedriver.exe')\n",
    "                driver_reply.implicitly_wait(3) #隐式等待 3 秒\n",
    "                driver_reply.get('https://www.icourse163.org/learn/CAU-23004?tid=1003114004#/learn/forumdetail?pid=1210924325')\n",
    "#                 driver_reply.quit()\n",
    "                reply_soup = BeautifulSoup(driver_reply.page_source, 'html.parser')\n",
    "                reply_list = reply_soup.find_all('div', class_='m-detailInfoItem')\n",
    "                for reply_item in reply_list:\n",
    "                    write_text = reply_item.find('div', class_='j-content')\n",
    "                    print(write_text.text)\n",
    "#                 driver_reply.close()\n",
    "                \n",
    "#                 reply_list=comment_list.find_all('p', class_='reply')\n",
    "#                 print(reply_list)\n",
    "\n",
    "#                 comment_lists = soup.find_all('li', class_='u-forumli')\n",
    "#                 print(len(comment_lists))\n",
    "#                 for comment in comment_lists:\n",
    "#                     reply_num = comment.find('p', class_='reply')\n",
    "#                     reply_num = int(reply_num.text[3:])\n",
    "            except Exception:\n",
    "                print('第{}页评论抓取失败！'.format(i))\n",
    "get_connect_slow_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def get_connect_slow_1(course_url, course_name):\n",
    "#     driver.switch_to.default_content() # 退出框架\n",
    "    pages = driver.find_elements_by_class_name('zpgi')\n",
    "    totle_page = int(pages[-1].text) #倒数第2个zpgi为最后一页,不一定\n",
    "    \n",
    "    for i in range(1, totle_page+1):\n",
    "            try:\n",
    "                driver.implicitly_wait(3)\n",
    "                url = url_head + '?t=0&p=' + str(i)\n",
    "                driver.get(url)\n",
    "                content = driver.page_source\n",
    "                soup = BeautifulSoup(content, 'lxml')\n",
    "                # course_title = soup.find('h4', class_='courseTxt')\n",
    "                # fi.write(course_title.text + '\\n')\n",
    "                comment_lists = soup.find_all('li', class_='u-forumli')\n",
    "                for comment in comment_lists:\n",
    "                    reply_num = comment.find('p', class_='reply')\n",
    "                    reply_num = int(reply_num.text[3:])\n",
    "                    if reply_num > 0:\n",
    "                        try:\n",
    "                            comment_detail = comment.find('a', class_='j-link')\n",
    "                            fi.write(comment_detail.text + '\\n')\n",
    "                            a_link = comment_detail.get('href')\n",
    "                            reply_link = url.split('#')[0] + a_link\n",
    "                            driver_reply = webdriver.Chrome(executable_path=chrome_driver)\n",
    "                            driver_reply.implicitly_wait(3) #隐式等待 3 秒\n",
    "                            driver_reply.get(reply_link)\n",
    "                            test_ = driver_reply.find_element_by_class_name('m-detailInfoItem')\n",
    "                            reply_soup = BeautifulSoup(driver_reply.page_source, 'lxml')\n",
    "                            # 楼主对主题的描述\n",
    "                            own_reply = reply_soup.find('div', class_='j-post')\n",
    "                            own_reply = own_reply.find('div', class_='j-content')\n",
    "                            # 有楼主对主题省去描述\n",
    "                            if own_reply.text:\n",
    "                                fi.write('\\t' + own_reply.text + '\\n')\n",
    "\n",
    "                            # 别人对该主题的评论回复\n",
    "                            reply_list = reply_soup.find_all('div', class_='m-detailInfoItem')\n",
    "                            for reply_item in reply_list:\n",
    "                                write_text = reply_item.find('div', class_='j-content')\n",
    "                                fi.write('\\t' + write_text.text + '\\n')\n",
    "                            driver_reply.close()\n",
    "                        except Exception :\n",
    "                            print('评论回复抓取失败！')\n",
    "                    else:\n",
    "                        fi.write(comment.find('a', class_='j-link').text + '\\n')\n",
    "                print('第{}页评论写入成功！'.format(i))\n",
    "            except Exception:\n",
    "                print('第{}页评论抓取失败！'.format(i))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
